<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Radiance Field - Project Results</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
        }

        header h1 {
            font-size: 3em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        header p {
            font-size: 1.2em;
            opacity: 0.95;
        }

        .content {
            padding: 40px;
        }

        section {
            margin-bottom: 60px;
        }

        section h2 {
            color: #667eea;
            font-size: 2em;
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 3px solid #667eea;
            position: relative;
        }

        section h3 {
            color: #764ba2;
            font-size: 1.5em;
            margin-top: 30px;
            margin-bottom: 20px;
        }

        .grid-2 {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-bottom: 30px;
        }

        .grid-3 {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 30px;
            margin-bottom: 30px;
        }

        .grid-4 {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 30px;
            margin-bottom: 30px;
        }

        .card {
            background: #f8f9fa;
            border-radius: 8px;
            padding: 25px;
            border-left: 5px solid #667eea;
            transition: transform 0.3s, box-shadow 0.3s;
        }

        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(102, 126, 234, 0.15);
        }

        .card h4 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.2em;
        }

        .card p {
            color: #555;
            margin-bottom: 10px;
        }

        .metric {
            font-weight: bold;
            color: #764ba2;
            font-size: 1.1em;
        }

        .image-container {
            text-align: center;
            margin: 30px 0;
        }

        .image-container img,
        .image-container video {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
            margin-bottom: 15px;
        }

        .image-label {
            color: #666;
            font-size: 0.95em;
            font-style: italic;
            margin-top: 10px;
        }

        .comparison-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 20px;
            margin: 30px 0;
        }

        .comparison-item {
            text-align: center;
        }

        .comparison-item img {
            width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        .comparison-label {
            margin-top: 10px;
            font-weight: bold;
            color: #667eea;
        }

        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d63384;
        }

        .code-block {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            line-height: 1.5;
        }

        .stats-box {
            background: linear-gradient(135deg, #667eea15 0%, #764ba215 100%);
            border-radius: 8px;
            padding: 25px;
            margin: 20px 0;
            border: 2px solid #667eea30;
        }

        .stat-row {
            display: grid;
            grid-template-columns: 200px 1fr;
            gap: 20px;
            margin-bottom: 15px;
            align-items: center;
        }

        .stat-label {
            font-weight: bold;
            color: #667eea;
        }

        .stat-value {
            color: #333;
            font-size: 1.05em;
        }

        .highlight {
            background-color: #fff3cd;
            padding: 2px 5px;
            border-radius: 3px;
        }

        .table-wrapper {
            overflow-x: auto;
            margin: 20px 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        th {
            background: #667eea;
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: bold;
        }

        td {
            padding: 12px 15px;
            border-bottom: 1px solid #e0e0e0;
        }

        tr:last-child td {
            border-bottom: none;
        }

        tr:nth-child(even) {
            background: #f8f9fa;
        }

        .achievement {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            text-align: center;
        }

        .achievement-title {
            font-size: 1.3em;
            font-weight: bold;
            margin-bottom: 5px;
        }

        .achievement-value {
            font-size: 2em;
            font-weight: bold;
        }

        .deliverables-checklist {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .checklist-item {
            padding: 12px;
            margin-bottom: 8px;
            background: white;
            border-radius: 4px;
            display: flex;
            align-items: center;
        }

        .checklist-item.done::before {
            content: "âœ“";
            color: #28a745;
            font-size: 1.5em;
            font-weight: bold;
            margin-right: 15px;
        }

        .checklist-item.done {
            color: #28a745;
            border-left: 4px solid #28a745;
        }

        footer {
            background: #f8f9fa;
            padding: 30px 40px;
            text-align: center;
            color: #666;
            border-top: 1px solid #e0e0e0;
        }

        .video-container {
            position: relative;
            width: 100%;
            padding-bottom: 56.25%;
            height: 0;
            overflow: hidden;
            border-radius: 8px;
            margin: 20px 0;
        }

        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
        }

        @media (max-width: 768px) {
            .grid-2, .grid-3, .grid-4 {
                grid-template-columns: 1fr;
            }
            
            header h1 {
                font-size: 2em;
            }
            
            .stat-row {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ðŸŽ¬ Neural Radiance Field</h1>
            <p>CS 280A Project - UC Berkeley</p>
        </header>

        <div class="content">
            <!-- PART 0 -->
            <section>
                <h2>Part 0: Camera Calibration & 3D Scanning</h2>
                
                <p>This section documents the camera calibration and 3D object scanning pipeline using ArUco markers for robust pose estimation.</p>

                <h3>Camera Calibration Results</h3>
                <div class="stats-box">
                    <div class="stat-row">
                        <div class="stat-label">Calibration Images:</div>
                        <div class="stat-value">80+ images with varying angles and distances</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">ArUco Tags:</div>
                        <div class="stat-value">4Ã—4 dictionary (DICT_4X4_50)</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Calibration Method:</div>
                        <div class="stat-value">cv2.calibrateCamera() with multiple views</div>
                    </div>
                </div>

                <h3>3D Object Scan</h3>
                <p>Captured 80+ images of the target object (<strong>Pou</strong>) with consistent zoom and lighting.</p>
                
                <div class="grid-2">
                    <div class="image-container">
                        <img src="camera1.png" alt="Camera Frustum Visualization 1">
                        <div class="image-label">Camera Frustums - View 1</div>
                    </div>
                    <div class="image-container">
                        <img src="camera2.png" alt="Camera Frustum Visualization 2">
                        <div class="image-label">Camera Frustums - View 2</div>
                    </div>
                </div>

                <h3>Pose Estimation</h3>
                <p>Used PnP (Perspective-n-Point) to solve for camera poses from detected ArUco markers.</p>
                <div class="card">
                    <h4>Key Implementation Details</h4>
                    <p>âœ“ Robust detection with frame skipping for failed detections</p>
                    <p>âœ“ Camera-to-world matrix inversion: <code>c2w = inv(w2c)</code></p>
                    <p>âœ“ Undistortion using <code>cv2.undistort()</code> with optimal camera matrix</p>
                    <p>âœ“ Principal point adjustment for cropped regions</p>
                </div>
            </section>

            <!-- PART 1 -->
            <section>
                <h2>Part 1: Neural Field for 2D Images</h2>
                
                <p>Training a neural field to fit 2D images using sinusoidal positional encoding and MLPs.</p>

                <h3>Model Architecture</h3>
                <div class="stats-box">
                    <div class="stat-row">
                        <div class="stat-label">Input Dimension:</div>
                        <div class="stat-value">2D pixel coordinates (normalized to [0, 1])</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Positional Encoding:</div>
                        <div class="stat-value">L_freq = 10, Output: 42D vector (2 + 2Ã—10Ã—2)</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Hidden Layers:</div>
                        <div class="stat-value">4 layers with varying widths (128, 256, 256, 128)</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Activation:</div>
                        <div class="stat-value">ReLU, final layer: Sigmoid for [0, 1] output</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Optimizer:</div>
                        <div class="stat-value">Adam with lr = 1e-2</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Training Iterations:</div>
                        <div class="stat-value">3000 iterations, batch size = 10,000 pixels</div>
                    </div>
                </div>

                <h3>Training Progression - Fox</h3>
                <div class="comparison-grid">
                    <div class="comparison-item">
                        <img src="part 1/fox/render_epoch_0.png" alt="Iteration 0">
                        <div class="comparison-label">Iter 0</div>
                    </div>
                    <div class="comparison-item">
                        <img src="part 1/fox/render_epoch_300.png" alt="Iteration 300">
                        <div class="comparison-label">Iter 300</div>
                    </div>
                    <div class="comparison-item">
                        <img src="part 1/fox/render_epoch_600.png" alt="Iteration 600">
                        <div class="comparison-label">Iter 600</div>
                    </div>
                    <div class="comparison-item">
                        <img src="part 1/fox/render_epoch_999.png" alt="Iteration 999">
                        <div class="comparison-label">Iter 999 (Final)</div>
                    </div>
                </div>

                <h3>Training Progression - My Cat!</h3>
                <p><em>Results on cat</em></p>
                <div class="comparison-grid">
                    <div class="comparison-item">
                        <img src="part 1/cat/render_epoch_0.png" alt="Cat - Iteration 0">
                        <div class="comparison-label">Iter 0</div>
                    </div>
                    <div class="comparison-item">
                        <img src="part 1/cat/render_epoch_999.png" alt="Cat - Iteration 999">
                        <div class="comparison-label">Iter 999 (Final)</div>
                    </div>
                </div>

                <h3>Hyperparameter Study: 2Ã—2 Grid</h3>
                <div class="grid-4">
                    <div class="image-container">
                        <img src="part 1/low_low/render_epoch_999.png" alt="L=4, Width=128">
                        <div class="image-label"><strong>L=4, Width=128</strong><br>Limited frequency, small model</div>
                    </div>
                    <div class="image-container">
                        <img src="part 1/low_high/render_epoch_999.png" alt="L=4, Width=256">
                        <div class="image-label"><strong>L=4, Width=256</strong><br>Limited frequency, larger model</div>
                    </div>
                    <div class="image-container">
                        <img src="part 1/high_low/render_epoch_999.png" alt="L=10, Width=128">
                        <div class="image-label"><strong>L=10, Width=128</strong><br>High frequency, small model</div>
                    </div>
                    <div class="image-container">
                        <img src="part 1/cat/render_epoch_999.png" alt="L=10, Width=256">
                        <div class="image-label"><strong>L=10, Width=256</strong><br>High frequency, large model (Best)</div>
                    </div>
                </div>

                <h3>PSNR Training Curve</h3>
                <div class="image-container">
                    <img src="part 1/cat/psnr_curve.png" alt="2D Training PSNR Curve">
                    <div class="image-label">Peak PSNR: ~33 dB at convergence</div>
                </div>
            </section>

            <!-- PART 2 -->
            <section>
                <h2>Part 2: Neural Radiance Field</h2>
                
                <p>Training a full 3D NeRF on the given multi-view lego images and pou (my own pictures).</p>

                <h3>Implementation Details</h3>
                
<h4>2.1 - Ray Generation</h4>
                <div class="stats-box">
                    <div class="stat-row">
                        <div class="stat-label">Pixel to Ray:</div>
                        <div class="stat-value">Convert 2D image coordinates to 3D rays in world space</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Formula:</div>
                        <div class="stat-value">ray_origin = c2w[:3, 3], ray_direction from pixel coordinates through intrinsic matrix K</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Offset:</div>
                        <div class="stat-value">Added 0.5 to pixel coordinates for pixel center sampling</div>
                    </div>
                </div>

                <h4>2.2 - Point Sampling</h4>
                <div class="stats-box">
                    <div class="stat-row">
                        <div class="stat-label">Uniform Sampling:</div>
                        <div class="stat-value">t = np.linspace(near=2.0, far=6.0, n_samples=64)</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Perturbation:</div>
                        <div class="stat-value">Added random noise during training to prevent overfitting</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">3D Points:</div>
                        <div class="stat-value">points = ray_origin + ray_direction * t</div>
                    </div>
                </div>

                <h4>2.3 - Data Loading</h4>
                <div class="stats-box">
                    <div class="stat-row">
                        <div class="stat-label">Ray Sampling:</div>
                        <div class="stat-value">10,240 rays per batch from ~100 training images</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Multi-image Sampling:</div>
                        <div class="stat-value">Global random sampling across all images</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Validation:</div>
                        <div class="stat-value">10 validation images for PSNR monitoring</div>
                    </div>
                </div>

                <h4>2.4 - NeRF Network Architecture</h4>
                <div class="stats-box">
                    <div class="stat-row">
                        <div class="stat-label">Position Encoding:</div>
                        <div class="stat-value">L_pos = 10 (63D vector)</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Direction Encoding:</div>
                        <div class="stat-value">L_dir = 4 (27D vector)</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Hidden Dimension:</div>
                        <div class="stat-value">256 neurons per layer</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Output:</div>
                        <div class="stat-value">Density (Ïƒ) + RGB Color (c)</div>
                    </div>
                </div>
                
                <h3>Network Architecture Diagram</h3>
                <div class="image-container">
                    <img src="NeRF.png" alt="NeRF Network Architecture">
                    <div class="image-label">NeRF MLP architecture with positional encoding and dense connections</div>
                </div>

                <h4>2.5 - Volume Rendering</h4>
                <div class="stats-box">
                    <div class="stat-row">
                        <div class="stat-label">Rendering Equation:</div>
                        <div class="stat-value">C(r) = Î£ T_i * Î±_i * c_i</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Transmittance (T_i):</div>
                        <div class="stat-value">Probability ray survives to sample i</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Alpha (Î±_i):</div>
                        <div class="stat-value">Î±_i = 1 - exp(-Ïƒ_i * Î”t)</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Color (c_i):</div>
                        <div class="stat-value">RGB color predicted by network</div>
                    </div>
                </div>

                <h3>Visualization: Rays & Samples</h3>
                <div class="image-container">
                    <img src="lego_rays.png" alt="Rays and Samples Visualization">
                    <div class="image-label">Rays from training cameras with sample points (black dots)</div>
                </div>

                <h3>Training Progression</h3>
                <div class="comparison-grid">
                    <div class="comparison-item">
                        <img src="lego/result/lego_iter0.png" alt="Lego Iteration 0">
                        <div class="comparison-label">Iter 0 (Random)</div>
                    </div>
                    <div class="comparison-item">
                        <img src="lego/result/lego_iter500.png" alt="Lego Iteration 500">
                        <div class="comparison-label">Iter 500</div>
                    </div>
                    <div class="comparison-item">
                        <img src="lego/result/lego_iter1000.png" alt="Lego Iteration 1000">
                        <div class="comparison-label">Iter 1000</div>
                    </div>
                    <div class="comparison-item">
                        <img src="lego/result/lego_iter4999.png" alt="Lego Iteration 4999">
                        <div class="comparison-label">Iter 4999 (Final)</div>
                    </div>
                </div>

                <h3>Validation PSNR Curve</h3>
                <div class="image-container">
                    <img src="lego/psnr_curve.png" alt="Lego PSNR Curve">
                    <div class="image-label">Peak PSNR: ~27.5 dB after 5000 iterations</div>
                </div>

                <h3>Novel View Synthesis - Spherical Video</h3>
                <p>Novel views rendered from unseen camera poses on a circular trajectory:</p>
                <div class="image-container">
                    <img src="lego/lego_novel_views.gif" alt="Lego Novel Views GIF">
                    <div class="image-label">Rendered from 60 unseen test camera poses</div>
                </div>

                <div class="achievement">
                    <div class="achievement-title">NeRF Quality Metrics</div>
                    <div class="achievement-value">27.5 dB PSNR</div>
                    <p style="margin-top: 10px; opacity: 0.9;">Successfully exceeded 23 dB target for full credit</p>
                </div>
            </section>

            <!-- PART 2.6 -->
            <section>
                <h2>Part 2.6: Training with Your Own Data</h2>
                
                <p>Custom NeRF training on a "Pou" using the dataset created in Part 0.</p>

                <h3>Dataset Information</h3>
                <div class="stats-box">
                    <div class="stat-row">
                        <div class="stat-label">Object:</div>
                        <div class="stat-value">Pou</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Training Images:</div>
                        <div class="stat-value">~80 images (undistorted)</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Image Resolution:</div>
                        <div class="stat-value">1280Ã—1707 (resized to 320Ã—426 for training)</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Near/Far Planes:</div>
                        <div class="stat-value">near=0.35, far=1.55 (adjusted for smaller object)</div>
                    </div>
                </div>

                <h3>Hyperparameter Changes</h3>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr>
                                <th>Parameter</th>
                                <th>Lego (Reference)</th>
                                <th>Pou (Our Object)</th>
                                <th>Reason</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>near / far</td>
                                <td>2.0 / 6.0</td>
                                <td>0.35 / 1.55</td>
                                <td>Different camera positions</td>
                            </tr>
                            <tr>
                                <td>n_samples</td>
                                <td>64</td>
                                <td>64</td>
                                <td>Same for quality</td>
                            </tr>
                            <tr>
                                <td>Image Resolution</td>
                                <td>200Ã—200</td>
                                <td>320Ã—426</td>
                                <td>Better detail capture</td>
                            </tr>
                            <tr>
                                <td>Learning Rate</td>
                                <td>5e-4</td>
                                <td>5e-4</td>
                                <td>Standard NeRF settings</td>
                            </tr>
                            <tr>
                                <td>Training Iterations</td>
                                <td>5000</td>
                                <td>5000</td>
                                <td>Same for detail learning</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <h3>Key Implementation Changes</h3>
                <div class="card">
                    <h4>1. Adaptive Near/Far Planes</h4>
                    <p>Computed optimal near/far from actual camera pose distribution rather than hardcoding</p>
                </div>
                <div class="card">
                    <h4>2. Increased Image Resolution</h4>
                    <p>Trained at higher resolution (320Ã—426) for better detail preservation</p>
                </div>
                <div class="card">
                    <h4>3. Better Undistortion</h4>
                    <p>Applied optimal camera matrix with ROI cropping to handle lens distortion</p>
                </div>
                <div class="card">
                    <h4>4. Training Loss Tracking</h4>
                    <p>Added loss history to checkpoint files for debugging and visualization</p>
                </div>

                <h3>Training Loss Over Iterations</h3>
                <div class="image-container">
                    <img src="pou/loss_curve.png" alt="Pou Training Loss Curve">
                    <div class="image-label">Converges after ~4000 iterations; MSE Loss: 0.05 â†’ 0.005</div>
                </div>

                <h3>Intermediate Renders During Training</h3>
                <div class="comparison-grid">
                    <div class="comparison-item">
                        <img src="pou/result/pou_iter0.png" alt="Iteration 0">
                        <div class="comparison-label">Iter 0 (Random)</div>
                    </div>
                    <div class="comparison-item">
                        <img src="pou/result/pou_iter400.png" alt="Iteration 400">
                        <div class="comparison-label">Iter 400</div>
                    </div>
                    <div class="comparison-item">
                        <img src="pou/result/pou_iter600.png" alt="Iteration 600">
                        <div class="comparison-label">Iter 600</div>
                    </div>
                    <div class="comparison-item">
                        <img src="pou/result/pou_iter4999.png" alt="Iteration 4999">
                        <div class="comparison-label">Iter 4999 (Final)</div>
                    </div>
                </div>

                <h3>Novel View GIF - Camera Circling Object</h3>
                <div class="image-container">
                    <img src="pou/novel_views.gif" alt="Pou Novel Views GIF" style="max-width: 500px; margin: 20px auto;">
                    <div class="image-label">60 frames of unseen camera poses circling the object</div>
                </div>

                <h3>Training Discussion</h3>
                <p>
                    The custom object training presented unique challenges compared to the lego scene:
                </p>
                <ul style="margin: 20px 40px; line-height: 2;">
                    <li><strong>Scale Adaptation:</strong> The dramatic difference in object size required retuning near/far planes by ~4Ã—</li>
                    <li><strong>Lighting Variability:</strong> Small variations in capture lighting resulted in artifacts</li>
                    <li><strong>Background Noise:</strong> Initial training failed with cluttered backgrounds. Using a plain background was essential</li>
                    <li><strong>Camera Calibration:</strong> Precise undistortion was criticalâ€”errors propagated through the entire pipeline</li>
                </ul>
            </section>

            <!-- BELLS & WHISTLES -->
            <section>
                <h2>Bells & Whistles: Depth Map Rendering</h2>

                <p>Rendered depth maps for the Lego scene by compositing per-point depths instead of colors in the volume rendering equation.</p>

                <h3>Depth Rendering Implementation</h3>
                <div class="card">
                    <h4>Modified Volume Rendering:</h4>
                    <p>Instead of: <code>C = Î£ T_i * Î±_i * c_i</code></p>
                    <p>We compute: <code>D = Î£ T_i * Î±_i * t_i</code></p>
                    <p>Where t_i is the sample distance along the ray.</p>
                </div>

                <h3>Depth Video Results</h3>
                <p>Visualized using viridis colormap (purple = near, yellow = far):</p>
                <div class="image-container">
                    <img src="lego/lego_depth.gif" alt="Lego Depth Map GIF">
                    <div class="image-label">Depth map video showing geometric structure of Lego scene</div>
                </div>

                <h3>Depth Map Details</h3>
                <div class="stats-box">
                    <div class="stat-row">
                        <div class="stat-label">Depth Range:</div>
                        <div class="stat-value">2.0 to 6.0 units</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Colormap:</div>
                        <div class="stat-value">Viridis (perceptually uniform)</div>
                    </div>
                    <div class="stat-row">
                        <div class="stat-label">Frames:</div>
                        <div class="stat-value">60 test camera poses</div>
                    </div>
                </div>
            </section>

            <!-- DELIVERABLES CHECKLIST -->
            <section>
                <h2>Deliverables Checklist</h2>
                
                <div class="deliverables-checklist">
                    <h3 style="color: #667eea; margin-top: 0;">Part 0: Camera Calibration & 3D Scanning</h3>
                    <div class="checklist-item done">2 screenshots of camera frustums visualization in Viser</div>

                    <h3 style="color: #667eea; margin-top: 20px;">Part 1: Neural Field for 2D Images</h3>
                    <div class="checklist-item done">Model architecture report (layers, width, learning rate)</div>
                    <div class="checklist-item done">Training progression on provided test image</div>
                    <div class="checklist-item done">Training progression on custom image</div>
                    <div class="checklist-item done">2Ã—2 grid: different encoding frequencies and widths</div>
                    <div class="checklist-item done">PSNR training curve</div>

                    <h3 style="color: #667eea; margin-top: 20px;">Part 2: NeRF from Multi-view Images</h3>
                    <div class="checklist-item done">Implementation description for each part (2.1-2.5)</div>
                    <div class="checklist-item done">Visualization of rays and samples with cameras</div>
                    <div class="checklist-item done">Training progression with predicted images</div>
                    <div class="checklist-item done">Validation PSNR curve</div>
                    <div class="checklist-item done">Spherical rendering video (novel view synthesis)</div>

                    <h3 style="color: #667eea; margin-top: 20px;">Part 2.6: Training with Own Data</h3>
                    <div class="checklist-item done">GIF of camera circling object with novel views</div>
                    <div class="checklist-item done">Discussion of code/hyperparameter changes</div>
                    <div class="checklist-item done">Plot of training loss over iterations</div>
                    <div class="checklist-item done">Intermediate renders during training</div>

                    <h3 style="color: #667eea; margin-top: 20px;">Bells & Whistles (CS 280A)</h3>
                    <div class="checklist-item done">Depth map video for Lego scene</div>
                </div>
            </section>

            <!-- SUMMARY -->
            <section>
                <h2>Project Summary</h2>
                
                <div class="achievement">
                    <div class="achievement-title">ðŸŽ¯ Objectives Achieved</div>
                </div>

                <div class="grid-3">
                    <div class="card">
                        <h4>âœ… 2D Image Fitting</h4>
                        <p>Successfully trained neural fields on 2D images with sinusoidal positional encoding, achieving 30+ dB PSNR.</p>
                    </div>
                    <div class="card">
                        <h4>âœ… 3D NeRF Training</h4>
                        <p>Implemented full multi-view NeRF pipeline on Lego dataset, reaching 27.5 dB PSNR target with novel view synthesis.</p>
                    </div>
                    <div class="card">
                        <h4>âœ… Custom Object Capture</h4>
                        <p>Created complete camera calibration pipeline and trained NeRF on personal object dataset with novel view rendering.</p>
                    </div>
                </div>

                <div class="grid-2">
                    <div class="card">
                        <h4>ðŸ“Š Technical Skills</h4>
                        <p>â€¢ PyTorch neural network implementation</p>
                        <p>â€¢ Camera calibration and pose estimation</p>
                        <p>â€¢ 3D coordinate transformations</p>
                        <p>â€¢ Volume rendering equations</p>
                        <p>â€¢ GPU optimization and batching</p>
                    </div>
                    <div class="card">
                        <h4>ðŸŽ¬ Results</h4>
                        <p>â€¢ 2D PSNR: ~33 dB</p>
                        <p>â€¢ Lego PSNR: 27.5 dB</p>
                        <p>â€¢ Novel view quality: Excellent</p>
                        <p>â€¢ Depth rendering: âœ“ Complete</p>
                        <p>â€¢ Training time: ~40 minutes for 5000 iters</p>
                    </div>
                </div>
            </section>
        </div>

        <footer>
            <p>Neural Radiance Field Project | CS 280A | UC Berkeley</p>
        </footer>
    </div>
</body>
</html>